{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import skimage.io as io\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from Model.UNetAttentionResNet import UNetAttentionResNet\n",
    "from Model.UNetAttentionDenseNet import UNetAttentionDenseNet\n",
    "from Model.UNetAttentionEfficientV2 import UNetAttentionEfficientV2\n",
    "from Model.UNetEfficientNetV2 import UNetEfficientV2\n",
    "\n",
    "from diodetools.DiodeLoader import DiodeDataLoader\n",
    "from diodetools.TrainTest import test, load_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengujian setiap model Attention U-Net dengan Pre-Trained\n",
    "res18   = load_model(\n",
    "    UNetAttentionResNet(device, 'resnet18'), \n",
    "    r'./SavedModel/resnet/resnet18_50_epoch_26-04-23.pt')\n",
    "res34   = load_model(\n",
    "    UNetAttentionResNet(device, 'resnet34'), \n",
    "    r'./SavedModel/resnet/resnet34_50_epoch_26-04-23.pt')\n",
    "res50   = load_model(\n",
    "    UNetAttentionResNet(device, 'resnet50'), \n",
    "    r'./SavedModel/resnet/resnet50_50_epoch_27-04-23.pt')\n",
    "res101  = load_model(\n",
    "    UNetAttentionResNet(device, 'resnet101'), \n",
    "    r'./SavedModel/resnet/resnet101_50_epoch_27-04-23.pt')\n",
    "res152  = load_model(\n",
    "    UNetAttentionResNet(device, 'resnet152'), \n",
    "    r'./SavedModel/resnet/resnet152_50_epoch_27-04-23.pt')\n",
    "\n",
    "den121  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet121'), \n",
    "    r'./SavedModel/densenet/densenet121_50_epoch_26-04-23.pt')\n",
    "den169  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet169'), \n",
    "    r'./SavedModel/densenet/densenet169_50_epoch_26-04-23.pt')\n",
    "den169_a  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet169', act=True), \n",
    "    r'./SavedModel/densenet/densenet169_act_50_epoch_25-04-23.pt')\n",
    "den201  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet201'), \n",
    "    r'./SavedModel/densenet/densenet201_50_epoch_26-04-23.pt')\n",
    "\n",
    "u_v2_s = load_model(\n",
    "    UNetAttentionEfficientV2(device, 'efficient_v2_s'), \n",
    "    r'./SavedModel/efficientnet/efficient_v2_s_50_epoch_28-04-23.pt')\n",
    "u_v2_m = load_model(\n",
    "    UNetAttentionEfficientV2(device, 'efficient_v2_m'), \n",
    "    r'./SavedModel/efficientnet/efficient_v2_m_50_epoch_28-04-23.pt')\n",
    "u_v2_l = load_model(\n",
    "    UNetAttentionEfficientV2(device, 'efficient_v2_l'), \n",
    "    r'./SavedModel/efficientnet/efficient_v2_l_50_epoch_28-04-23.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengujian model arsitektur U-Net dengan Attention U-Net\n",
    "u_v2_s = load_model(\n",
    "    UNetAttentionEfficientV2(device, 'efficient_v2_s'), \n",
    "    r'./SavedModel/efficientnet/efficient_v2_s_50_epoch_28-04-23.pt')\n",
    "u_v2_m = load_model(\n",
    "    UNetAttentionEfficientV2(device, 'efficient_v2_m'), \n",
    "    r'./SavedModel/efficientnet/efficient_v2_m_50_epoch_28-04-23.pt')\n",
    "u_v2_l = load_model(\n",
    "    UNetAttentionEfficientV2(device, 'efficient_v2_l'), \n",
    "    r'./SavedModel/efficientnet/efficient_v2_l_50_epoch_28-04-23.pt')\n",
    "\n",
    "noag_u_v2_s = load_model(\n",
    "    UNetEfficientV2(device, 'efficient_v2_s'), \n",
    "    r'./SavedModel/noag_efficientnet/NoAG_UNet_efficient_v2_s_50_epoch_28-04-23.pt')\n",
    "noag_u_v2_m = load_model(\n",
    "    UNetEfficientV2(device, 'efficient_v2_m'), \n",
    "    r'./SavedModel/noag_efficientnet/NoAG_UNet_efficient_v2_m_50_epoch_28-04-23.pt')\n",
    "noag_u_v2_l = load_model(\n",
    "    UNetEfficientV2(device, 'efficient_v2_l'), \n",
    "    r'./SavedModel/noag_efficientnet/NoAG_UNet_efficient_v2_l_50_epoch_28-04-23.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengujian pengaruh fungsi aktivasi di head block \n",
    "den169_no  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet169', act=False), \n",
    "    r'./SavedModel/densenet/densenet169_50_epoch_26-04-23.pt')\n",
    "\n",
    "den169_act  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet169', act=True), \n",
    "    r'./SavedModel/densenet/densenet169_act_50_epoch_26-04-23.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test indoor : (325, 3)\n",
      "Test outdoor : (446, 3)\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(1)\n",
    "\n",
    "def getData(path):\n",
    "    filelist = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            filelist.append(os.path.join(root, file))\n",
    "\n",
    "    filelist.sort()\n",
    "    data = {\n",
    "        \"image\": [x for x in filelist if x.endswith(\".png\")],\n",
    "        \"depth\": [x for x in filelist if x.endswith(\"_depth.npy\")],\n",
    "        \"mask\": [x for x in filelist if x.endswith(\"_depth_mask.npy\")],\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df_test = getData(r'../datasets/diode/val/indoors/')\n",
    "df_outdoor_test = getData(r'../datasets/diode/val/outdoor/')\n",
    "print(f\"Test indoor : {df_test.shape}\")\n",
    "print(f\"Test outdoor : {df_outdoor_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "max_depth = 50\n",
    "models = [res18, res34, res50, res101, res152]\n",
    "models_name = ['res-18', 'res-34', 'res-50', 'res-101', 'res-152']\n",
    "\n",
    "def testing_all_model(loader, models, models_name, max_depth):\n",
    "    for model, model_name in zip(models, models_name):\n",
    "        print(model_name)\n",
    "        test(model=model, l1_weight=0.1, loader=loader, max_depth=max_depth, device='cuda')\n",
    "        print()\n",
    "        \n",
    "        del model\n",
    "\n",
    "testloader = DataLoader(\n",
    "                    DiodeDataLoader(df_test, max_depth=max_depth, img_dim=(192, 256), depth_dim=(192, 256)), \n",
    "                    batch_size=16, \n",
    "                    shuffle=False\n",
    "                )\n",
    "\n",
    "testing_all_model(testloader, models, models_name, max_depth)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "max_depth = 50\n",
    "models = [den121, den169, den201]\n",
    "models_name = ['den-121', 'den-169', 'den-201']\n",
    "\n",
    "def testing_all_model(loader, models, models_name, max_depth):\n",
    "    for model, model_name in zip(models, models_name):\n",
    "        print(model_name)\n",
    "        test(model=model, l1_weight=0.1, loader=loader, max_depth=max_depth, device='cuda')\n",
    "        print()\n",
    "        \n",
    "        del model\n",
    "\n",
    "testloader = DataLoader(\n",
    "                    DiodeDataLoader(df_test, max_depth=max_depth, img_dim=(192, 256), depth_dim=(192, 256)), \n",
    "                    batch_size=16, \n",
    "                    shuffle=False\n",
    "                )\n",
    "\n",
    "testing_all_model(testloader, models, models_name, max_depth)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet with act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "max_depth = 50\n",
    "testloader = DataLoader(\n",
    "                    DiodeDataLoader(df_test, max_depth=max_depth, img_dim=(192, 256), depth_dim=(192, 256)), \n",
    "                    batch_size=16, \n",
    "                    shuffle=True\n",
    "                )\n",
    "\n",
    "print(f'den169_a')\n",
    "test(model=den169_a, l1_weight=0.1, loader=testloader, max_depth=max_depth, device='cuda')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet V2 Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "max_depth = 50\n",
    "models = [ef_s, ef_m, ef_l]\n",
    "models_name = ['ef-V2-s', 'ef-V2-m', 'ef-V2-l']\n",
    "\n",
    "def testing_all_model(loader, models, models_name, max_depth):\n",
    "    for model, model_name in zip(models, models_name):\n",
    "        print(model_name)\n",
    "        test(model=model, l1_weight=0.1, loader=loader, max_depth=max_depth, device='cuda')\n",
    "        print()\n",
    "        \n",
    "        del model\n",
    "\n",
    "testloader = DataLoader(\n",
    "                    DiodeDataLoader(df_test, max_depth=max_depth, img_dim=(192, 256), depth_dim=(192, 256)), \n",
    "                    batch_size=32, \n",
    "                    shuffle=False\n",
    "                )\n",
    "\n",
    "testing_all_model(testloader, models, models_name, max_depth)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No AG - EfficientNet V2 Variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "max_depth = 50\n",
    "models = [u_v2_s, u_v2_m, u_v2_l]\n",
    "models_name = ['UE-S', 'UE-M', 'UE-L']\n",
    "\n",
    "def testing_all_model(loader, models, models_name, max_depth):\n",
    "    for model, model_name in zip(models, models_name):\n",
    "        print(model_name)\n",
    "        test(model=model, l1_weight=0.1, loader=loader, max_depth=max_depth, device='cuda')\n",
    "        print()\n",
    "        \n",
    "        del model\n",
    "\n",
    "testloader = DataLoader(\n",
    "                    DiodeDataLoader(df_test, max_depth=max_depth, img_dim=(192, 256), depth_dim=(192, 256)), \n",
    "                    batch_size=32, \n",
    "                    shuffle=False\n",
    "                )\n",
    "\n",
    "testing_all_model(testloader, models, models_name, max_depth)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "max_depth = 50\n",
    "loader = DataLoader(\n",
    "            DiodeDataLoader(df_test, max_depth=max_depth, img_dim=(192, 256), depth_dim=(192, 256)), \n",
    "            batch_size=128, \n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : torch.Size([128, 3, 192, 256])\n",
      "Depth: torch.Size([128, 1, 192, 256])\n"
     ]
    }
   ],
   "source": [
    "data, depth = next(iter(loader))\n",
    "print(f\"Data : {data.shape}\")\n",
    "print(f\"Depth: {depth.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize \n",
    "def visualize(show_idx, models, models_name, cmap='inferno'):\n",
    "    with torch.no_grad():\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2 + len(models), figsize=(24, 22))\n",
    "        ax[0].set_title('Image', fontsize=15)\n",
    "        ax[1].set_title('DepthMap (GT)', fontsize=15)\n",
    "        \n",
    "        ax[0].imshow(data[show_idx].permute(1, 2, 0))\n",
    "        ax[1].imshow(depth[show_idx].squeeze(), cmap=cmap)\n",
    "        \n",
    "        start_show_idx = 2\n",
    "        for model, model_name in (zip(models, models_name)):\n",
    "            model.eval()\n",
    "            ax[start_show_idx].set_title(model_name, fontsize=14)\n",
    "            pred = model(data[show_idx][np.newaxis].to(device)).squeeze().cpu()\n",
    "            ax[start_show_idx].imshow(pred, cmap=cmap)\n",
    "        \n",
    "            start_show_idx += 1\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'inferno'\n",
    "\n",
    "for idx in range(128):\n",
    "    print(f'[{idx}]---'*20)\n",
    "    visualize(idx, \n",
    "        [den169_no, den169_act], \n",
    "        ['DenseNet-169 [No Act]', 'DenseNet-169 [With Act]'], \n",
    "        cmap=cmap\n",
    "    )\n",
    "    # visualize(idx, \n",
    "    #             [res18, res34, res50, res101, res152], \n",
    "    #             ['ResNet-18', 'ResNet-34', 'ResNet-50', 'ResNet-101', 'ResNet-152'], \n",
    "    #             cmap=cmap)\n",
    "    # visualize(idx, \n",
    "    #             [den121, den169, den201], \n",
    "    #             ['DenseNet-121', 'DenseNet-169', 'DenseNet-201'], \n",
    "    #             cmap=cmap)\n",
    "    # visualize(idx, \n",
    "    #             [u_v2_s, u_v2_m, u_v2_l], \n",
    "    #             ['EfficientNet-V2-S [U]', 'EfficientNet-V2-M [U]', 'EfficientNet-V2-L [U]'], \n",
    "    #             cmap=cmap)\n",
    "    # visualize(idx, \n",
    "    #             [noag_u_v2_s, noag_u_v2_m, noag_u_v2_l], \n",
    "    #             ['EfficientNet-V2-S [W]', 'EfficientNet-V2-M [W]', 'EfficientNet-V2-L [W]'], \n",
    "    #             cmap=cmap)\n",
    "    print('---'*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize \n",
    "def custom_visualize(img_path, models, models_name, device, cmap='inferno'):\n",
    "    with torch.no_grad():\n",
    "        trans = transforms.Compose([\n",
    "                        transforms.ToTensor(), \n",
    "                        transforms.Resize((256, 256))\n",
    "                    ])\n",
    "        img = io.imread(img_path)\n",
    "        img = trans(img[:, :, :3]).to(device)\n",
    "        \n",
    "        start_show_idx = 1\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=start_show_idx+len(models), figsize=(16, 22))\n",
    "        ax[0].set_title('Image', fontsize=15)\n",
    "        ax[0].imshow(img.permute(1, 2, 0).cpu())\n",
    "        \n",
    "        for model, model_name in (zip(models, models_name)):\n",
    "            model.eval()\n",
    "            ax[start_show_idx].set_title(model_name, fontsize=15)\n",
    "            pred = model(img[None, :, :, :]).squeeze().cpu()\n",
    "            ax[start_show_idx].imshow(pred, cmap=cmap)\n",
    "        \n",
    "            start_show_idx += 1\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "custom_visualize(\n",
    "    img_path='./TestSample/uji (1).png', \n",
    "    models=models, \n",
    "    models_name=models_name, \n",
    "    device=device,\n",
    "    cmap='inferno'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "model_name = ['DenseNet-121', 'DenseNet-169', 'DenseNet-169 [Act]', 'DenseNet-201', \n",
    "                'ResNet-101', 'ResNet-152', 'ResNet-18', 'ResNet-34', 'ResNet-50']\n",
    "df_readed = [] \n",
    "\n",
    "for path in os.listdir('./TrainingHistory/'): \n",
    "    print(path)\n",
    "    df_readed.append(pd.read_csv('./TrainingHistory/' + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show RMSE\n",
    "show_cols = ['rmse', 'rel', 'acc_1', 'acc_2', 'acc_3']\n",
    "est_cols = ['RMSE', 'REL', '$\\delta$ < 1.25', '$\\delta$ < 1.25^2', '$\\delta$ < 1.25^3']\n",
    "\n",
    "figsize_show_per_row = (20, 45)\n",
    "figsize_show_per_cols = (30, 6)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=figsize_show_per_row)\n",
    "for i in range(len(show_cols)):\n",
    "    ax[i].set_title(est_cols[i], fontsize=15)\n",
    "    ax[i].grid(True)\n",
    "    for df, model in zip(df_readed, model_name): \n",
    "        ax[i].plot(df[show_cols[i]][39:], label=model, lw=2)\n",
    "\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengujian pengaruh fungsi aktivasi di head block \n",
    "# kasih nama \"model\"\n",
    "den169_no  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet169', act=False), \n",
    "    r'./SavedModel/densenet/densenet169_50_epoch_26-04-23.pt')\n",
    "\n",
    "den169_act  = load_model(\n",
    "    UNetAttentionDenseNet(device, 'densenet169', act=True), \n",
    "    r'./SavedModel/densenet/densenet169_act_50_epoch_26-04-23.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import transforms\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_frame_time, new_frame_time = 0., 0.\n",
    "\n",
    "width, height = cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "down_resizer = transforms.Resize(size=(192, 256))\n",
    "up_resizer = transforms.Resize(size=(int(height), int(width)))\n",
    "\n",
    "max_depth = 50.\n",
    "inference_time_history = []\n",
    "inference_fps_history = []\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "elapsed_time = time.time()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        processed_frame = torch.tensor(np.array([frame])).permute(0, 3, 1, 2).to(device) / 255.\n",
    "        processed_mde_frame = down_resizer(processed_frame).to(device)\n",
    "        \n",
    "        # mde_output = up_resizer(mde_model(processed_mde_frame))[0][0]\n",
    "        inference_starttime = time.time()\n",
    "        #! Konfigurasi model disini\n",
    "        pred = den169_no(processed_mde_frame)\n",
    "        inference_endtime = time.time()\n",
    "        inference_time_history.append(inference_endtime - inference_starttime)\n",
    "        \n",
    "        new_frame_time = time.time() \n",
    "        fps = 1/(new_frame_time-prev_frame_time) \n",
    "        prev_frame_time = new_frame_time \n",
    "        fps = str(int(fps))\n",
    "        inference_fps_history.append(fps)\n",
    "        \n",
    "        mde_output = up_resizer(pred)[0][0]\n",
    "        mde_output = mde_output * max_depth\n",
    "        pred_color = ((mde_output - mde_output.min()) / (mde_output.max() - mde_output.min()) * 255)\n",
    "        pred_color = pred_color.cpu().detach().numpy()\n",
    "        pred_color = cv2.applyColorMap(pred_color.astype('uint8'), cv2.COLORMAP_INFERNO)\n",
    "        \n",
    "        cv2.putText(pred_color, f\"FPS : {fps}\", (7, 70), font, 3, (100, 255, 0), 2, cv2.LINE_AA) \n",
    "        cv2.imshow(\"RGB Input\", frame)\n",
    "        cv2.imshow(\"DepthMap Inference\", pred_color)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        done = int(time.time() - elapsed_time) == 9999\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\") or done:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU - Dense169 No Act\n",
      "------------------------------\n",
      "Inference TIME history: \n",
      "first 100 : [0.06483316421508789, 0.04733538627624512, 0.052243709564208984, 0.04712820053100586, 0.0510258674621582, 0.04224586486816406, 0.0519256591796875, 0.04537820816040039, 0.04445838928222656, 0.047458648681640625, 0.04638957977294922, 0.04155731201171875, 0.045577049255371094, 0.044261932373046875, 0.0483705997467041, 0.04857945442199707, 0.04734659194946289, 0.04752373695373535, 0.04270029067993164, 0.04545998573303223, 0.05310845375061035, 0.0413663387298584, 0.04220438003540039, 0.041570186614990234, 0.04124808311462402, 0.04930567741394043, 0.04368782043457031, 0.048261165618896484, 0.04509758949279785, 0.045656442642211914, 0.04411673545837402, 0.048723697662353516, 0.046762943267822266, 0.0444638729095459, 0.043590545654296875, 0.04419684410095215, 0.04396200180053711, 0.045903682708740234, 0.045479774475097656, 0.04401683807373047, 0.04131770133972168, 0.05195188522338867, 0.04407143592834473, 0.04891777038574219, 0.048029422760009766, 0.04996633529663086, 0.04581618309020996, 0.04672670364379883, 0.050896644592285156, 0.04599952697753906, 0.041860342025756836, 0.04116559028625488, 0.04099702835083008, 0.03831672668457031, 0.04215264320373535, 0.042069196701049805, 0.04124188423156738, 0.04125499725341797, 0.060866355895996094, 0.04456949234008789, 0.047858476638793945, 0.04808402061462402, 0.04806327819824219, 0.04627227783203125, 0.04532623291015625, 0.04953122138977051, 0.041554927825927734, 0.04096221923828125, 0.04085564613342285, 0.047080039978027344, 0.04744839668273926, 0.04544329643249512, 0.048087358474731445, 0.04613971710205078, 0.04140734672546387, 0.04735994338989258, 0.047502756118774414, 0.04576539993286133, 0.04166007041931152, 0.04112362861633301, 0.04456520080566406, 0.05110812187194824, 0.043573617935180664, 0.045734405517578125, 0.06030774116516113, 0.04924416542053223, 0.04103684425354004, 0.04547286033630371, 0.04435563087463379, 0.04498863220214844, 0.04661250114440918, 0.04410600662231445, 0.052961111068725586, 0.04429936408996582, 0.04157733917236328, 0.045711517333984375, 0.05260491371154785, 0.04692864418029785, 0.051152944564819336, 0.05546689033508301]\n",
      "Mean   : 0.04353310919215537\n",
      "Median : 0.04220438003540039\n",
      "------------------------------\n",
      "Inference FPS history: \n",
      "first 100 : ['0', '7', '9', '11', '11', '11', '10', '12', '11', '11', '11', '12', '11', '11', '11', '11', '11', '11', '12', '11', '10', '11', '11', '12', '12', '10', '12', '11', '12', '12', '11', '11', '11', '11', '12', '12', '12', '11', '11', '12', '12', '11', '11', '11', '11', '11', '12', '11', '11', '11', '12', '11', '12', '12', '11', '11', '12', '12', '9', '11', '11', '11', '11', '11', '11', '11', '12', '12', '11', '11', '11', '12', '11', '12', '12', '11', '11', '11', '12', '12', '11', '11', '11', '11', '10', '11', '12', '11', '11', '12', '11', '12', '10', '11', '12', '11', '10', '11', '11', '10']\n",
      "Mean   : 11.512820512820513\n",
      "Median : 12.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU - Dense169 No Act\")\n",
    "print('---'*10)\n",
    "print(f\"Inference TIME history: \")\n",
    "print(f\"first 100 : {inference_time_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_time_history).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_time_history))}\")\n",
    "print('---'*10)\n",
    "print(f\"Inference FPS history: \")\n",
    "print(f\"first 100 : {inference_fps_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_fps_history, dtype=np.int16).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_fps_history, dtype=np.int16))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU - Dense169 With Act\n",
      "------------------------------\n",
      "Inference TIME history: \n",
      "first 100 : [0.04695391654968262, 0.041591644287109375, 0.052107810974121094, 0.05348777770996094, 0.04865217208862305, 0.04351401329040527, 0.0447232723236084, 0.044267892837524414, 0.03969979286193848, 0.04480481147766113, 0.045406341552734375, 0.04595303535461426, 0.06192207336425781, 0.04684305191040039, 0.04860734939575195, 0.04568886756896973, 0.04763960838317871, 0.04757404327392578, 0.04561328887939453, 0.045973777770996094, 0.04426217079162598, 0.041623830795288086, 0.04126310348510742, 0.05849599838256836, 0.04195690155029297, 0.043096303939819336, 0.04178428649902344, 0.04846334457397461, 0.040204763412475586, 0.04697537422180176, 0.04510140419006348, 0.04494357109069824, 0.04150557518005371, 0.04117131233215332, 0.04754137992858887, 0.0445706844329834, 0.042374372482299805, 0.04101848602294922, 0.04434466361999512, 0.04394197463989258, 0.04094862937927246, 0.04858541488647461, 0.04601001739501953, 0.04199481010437012, 0.04782533645629883, 0.06485939025878906, 0.043016910552978516, 0.041570186614990234, 0.04139280319213867, 0.04159283638000488, 0.045615196228027344, 0.05750775337219238, 0.04606986045837402, 0.042638301849365234, 0.0446927547454834, 0.055481910705566406, 0.044170379638671875, 0.041541337966918945, 0.04167318344116211, 0.04545783996582031, 0.05691194534301758, 0.05941200256347656, 0.04295849800109863, 0.04826235771179199, 0.04391360282897949, 0.04100847244262695, 0.05008387565612793, 0.04139137268066406, 0.047635555267333984, 0.04600119590759277, 0.04003167152404785, 0.040871381759643555, 0.04117250442504883, 0.04132699966430664, 0.04459738731384277, 0.05083584785461426, 0.04632401466369629, 0.06081676483154297, 0.046675920486450195, 0.046933889389038086, 0.04193568229675293, 0.047946929931640625, 0.05145096778869629, 0.04140186309814453, 0.040923357009887695, 0.04059886932373047, 0.04116344451904297, 0.04141378402709961, 0.0411074161529541, 0.047083139419555664, 0.040350914001464844, 0.04861044883728027, 0.04635453224182129, 0.04533243179321289, 0.04799675941467285, 0.04323244094848633, 0.04482889175415039, 0.04176211357116699, 0.050174713134765625, 0.044336557388305664]\n",
      "Mean   : 0.04361633765391815\n",
      "Median : 0.04197072982788086\n",
      "------------------------------\n",
      "Inference FPS history: \n",
      "first 100 : ['0', '8', '9', '9', '11', '11', '11', '11', '12', '11', '11', '11', '10', '11', '11', '11', '11', '11', '11', '11', '12', '12', '12', '10', '12', '12', '11', '11', '12', '11', '12', '11', '11', '12', '11', '11', '12', '12', '12', '12', '11', '11', '12', '11', '11', '9', '12', '12', '12', '11', '11', '10', '11', '11', '12', '10', '11', '12', '12', '11', '10', '10', '12', '11', '12', '12', '11', '12', '11', '11', '12', '11', '11', '12', '11', '10', '11', '10', '11', '11', '11', '11', '11', '12', '12', '12', '12', '11', '11', '11', '12', '10', '11', '11', '11', '12', '11', '12', '11', '11']\n",
      "Mean   : 11.498575498575498\n",
      "Median : 12.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU - Dense169 With Act\")\n",
    "print('---'*10)\n",
    "print(f\"Inference TIME history: \")\n",
    "print(f\"first 100 : {inference_time_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_time_history).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_time_history))}\")\n",
    "print('---'*10)\n",
    "print(f\"Inference FPS history: \")\n",
    "print(f\"first 100 : {inference_fps_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_fps_history, dtype=np.int16).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_fps_history, dtype=np.int16))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU - Dense169 No Act\n",
      "------------------------------\n",
      "Inference TIME history: \n",
      "first 100 : [0.5262935161590576, 0.5190770626068115, 0.5224490165710449, 0.5101594924926758, 0.5230436325073242, 0.5121700763702393, 0.505425214767456, 0.5272402763366699, 0.5401570796966553, 0.5262546539306641, 0.5223908424377441, 0.5118429660797119, 0.49611830711364746, 0.5438647270202637, 0.5300309658050537, 0.4918191432952881, 0.45496082305908203, 0.47216248512268066, 0.46979475021362305, 0.4504714012145996, 0.48539090156555176, 0.45993852615356445, 0.4789109230041504, 0.46024298667907715, 0.4696178436279297, 0.5038902759552002, 0.5176773071289062, 0.5033471584320068, 0.4846529960632324, 0.5313174724578857, 0.5314376354217529, 0.47928285598754883, 0.5047035217285156, 0.44310569763183594, 0.4431922435760498, 0.46878767013549805, 0.47182297706604004, 0.4660048484802246, 0.45532965660095215, 0.4368577003479004, 0.4482455253601074, 0.45197296142578125, 0.47170567512512207, 0.45232701301574707, 0.45357251167297363, 0.43947529792785645, 0.4703655242919922, 0.43729257583618164, 0.4670712947845459, 0.44193172454833984, 0.4475431442260742, 0.45214343070983887, 0.4389073848724365, 0.44626331329345703, 0.44670724868774414, 0.4490518569946289, 0.45157790184020996, 0.4440155029296875]\n",
      "Mean   : 0.4803690951446007\n",
      "Median : 0.47103559970855713\n",
      "------------------------------\n",
      "Inference FPS history: \n",
      "first 100 : ['0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '2', '2', '2', '2', '1', '2', '2', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n",
      "Mean   : 1.4482758620689655\n",
      "Median : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"CPU - Dense169 No Act\")\n",
    "print('---'*10)\n",
    "print(f\"Inference TIME history: \")\n",
    "print(f\"first 100 : {inference_time_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_time_history).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_time_history))}\")\n",
    "print('---'*10)\n",
    "print(f\"Inference FPS history: \")\n",
    "print(f\"first 100 : {inference_fps_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_fps_history, dtype=np.int16).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_fps_history, dtype=np.int16))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU - Dense169 No Act\n",
      "------------------------------\n",
      "Inference TIME history: \n",
      "first 100 : [0.6051533222198486, 0.5283207893371582, 0.5023379325866699, 0.5261940956115723, 0.5406365394592285, 0.5500223636627197, 0.5279295444488525, 0.5205621719360352, 0.5181512832641602, 0.535017728805542, 0.5432651042938232, 0.5181839466094971, 0.5475635528564453, 0.5119552612304688, 0.5495162010192871, 0.5416994094848633, 0.5161535739898682, 0.5486240386962891, 0.4540979862213135, 0.4520761966705322, 0.47326064109802246, 0.4770956039428711, 0.5126292705535889, 0.4666292667388916, 0.4626476764678955, 0.48770785331726074, 0.45062780380249023, 0.4706284999847412, 0.4646482467651367, 0.4726529121398926, 0.46959948539733887, 0.4931173324584961, 0.4691164493560791, 0.4750971794128418, 0.4680898189544678, 0.49671125411987305, 0.4844231605529785, 0.5066711902618408, 0.503636360168457, 0.5276827812194824, 0.5066385269165039, 0.5632688999176025, 0.4826009273529053, 0.4626476764678955, 0.44463491439819336, 0.44133520126342773, 0.46462488174438477, 0.4626288414001465, 0.48267221450805664, 0.46262240409851074, 0.47760677337646484, 0.4726712703704834, 0.4586162567138672, 0.4696829319000244, 0.5096111297607422]\n",
      "Mean   : 0.4969453941692005\n",
      "Median : 0.48770785331726074\n",
      "------------------------------\n",
      "Inference FPS history: \n",
      "first 100 : ['0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1']\n",
      "Mean   : 1.1818181818181819\n",
      "Median : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"CPU - Dense169 No Act\")\n",
    "print('---'*10)\n",
    "print(f\"Inference TIME history: \")\n",
    "print(f\"first 100 : {inference_time_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_time_history).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_time_history))}\")\n",
    "print('---'*10)\n",
    "print(f\"Inference FPS history: \")\n",
    "print(f\"first 100 : {inference_fps_history[:100]}\")\n",
    "print(f\"Mean   : {np.array(inference_fps_history, dtype=np.int16).mean()}\")\n",
    "print(f\"Median : {np.median(np.array(inference_fps_history, dtype=np.int16))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
